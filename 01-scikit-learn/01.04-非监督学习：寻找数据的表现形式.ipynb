{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类：将数据结合在一起\n",
    "**聚类解决的问题**\n",
    "\n",
    "给定数据集，比如说鸢尾花的数据集。如果我们知道它有三种类别，但是不知道它们各自的标签。\n",
    "\n",
    "这个时候我们面临着一个聚类的任务：分割一个没有标签的数据集。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means聚类\n",
    "K-means是最简单的聚类方法\n",
    "\n",
    "对于鸢尾花的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 1 1 1 1 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster, datasets\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X_iris) \n",
    "\n",
    "print(k_means.labels_[::10])\n",
    "\n",
    "print(y_iris[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用实例：向量量化\n",
    "通常，聚类算法可以被认为是数据压缩的一种方式。\n",
    "\n",
    "这个问题有时候可以被认为是[向量量化](https://www.wikiwand.com/zh/%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96)\n",
    "\n",
    "例如，可以用于色调分离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "try:\n",
    "   face = sp.face(gray=True)\n",
    "except AttributeError:\n",
    "   from scipy import misc\n",
    "   face = misc.face(gray=True)\n",
    "X = face.reshape((-1, 1)) # We need an (n_sample, n_feature) array\n",
    "k_means = cluster.KMeans(n_clusters=5, n_init=1)\n",
    "k_means.fit(X) \n",
    "\n",
    "values = k_means.cluster_centers_.squeeze()\n",
    "labels = k_means.labels_\n",
    "face_compressed = np.choose(labels, values)\n",
    "face_compressed.shape = face.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 凝聚层次聚类（Hierarchical agglomerative clustering）：ward方法\n",
    "层次聚类方法是一个典型的方法聚类方法，它建立一个有等级的聚类。\n",
    "\n",
    "一般来说，各种层次凝聚方法可以分为两个类别：\n",
    "- 凝聚（Agglomerative）方法：自底向上聚类。当聚类的类别很大时候，计算效率远远小于K-means.\n",
    "- 分裂（Divisive ）方法：自顶向下聚类。很慢，不建议使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征凝聚（Feature agglomeration）\n",
    "在监督学习那部分中，我们已经学习了在多维稀疏空间中，使用正则化和lasso方法来避免维度灾难。\n",
    "\n",
    "另外一种方法是**将相似的特征融合在一起**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "images = digits.images\n",
    "X = np.reshape(images, (len(images), -1))\n",
    "connectivity = grid_to_graph(*images[0].shape)\n",
    "\n",
    "agglo = cluster.FeatureAgglomeration(connectivity=connectivity,\n",
    "                                     n_clusters=32)\n",
    "agglo.fit(X) \n",
    "\n",
    "X_reduced = agglo.transform(X)\n",
    "\n",
    "X_approx = agglo.inverse_transform(X_reduced)\n",
    "images_approx = np.reshape(X_approx, images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降维\n",
    "### 主成分分析：PCA\n",
    "PCA选择解释信号最大波动的连续组件\n",
    "\n",
    "例子如下：\n",
    "x3特征由x1和x2生成，所以可以用PCA降维成二维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.44021152e+00   8.13338862e-01   2.28913486e-32]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a signal with only 2 useful dimensions\n",
    "x1 = np.random.normal(size=100)\n",
    "x2 = np.random.normal(size=100)\n",
    "x3 = x1 + x2\n",
    "X = np.c_[x1, x2, x3]\n",
    "\n",
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "\n",
    "print(pca.explained_variance_)  \n",
    "\n",
    "\n",
    "# As we can see, only the 2 first components are useful\n",
    "pca.n_components = 2\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独立组件分析（Independent Component Analysis:ICA）\n",
    "ICA选择那些携带了最多独立信息的部件。其能够恢复非高斯的独立信号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate sample data\n",
    "time = np.linspace(0, 10, 2000)\n",
    "s1 = np.sin(2 * time)  # Signal 1 : sinusoidal signal\n",
    "s2 = np.sign(np.sin(3 * time))  # Signal 2 : square signal\n",
    "S = np.c_[s1, s2]\n",
    "S += 0.2 * np.random.normal(size=S.shape)  # Add noise\n",
    "S /= S.std(axis=0)  # Standardize data\n",
    "# Mix data\n",
    "A = np.array([[1, 1], [0.5, 2]])  # Mixing matrix\n",
    "X = np.dot(S, A.T)  # Generate observations\n",
    "\n",
    "# Compute ICA\n",
    "ica = decomposition.FastICA()\n",
    "S_ = ica.fit_transform(X)  # Get the estimated sources\n",
    "A_ = ica.mixing_.T\n",
    "np.allclose(X,  np.dot(S_, A_) + ica.mean_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
